<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.0.0-beta.1 for Hugo"><meta name=author content="Bella Nicholson"><meta name=description content="A study in pushing state-of-the-art computer vision models to their performance limits on iOS, balancing model capacity against real-world edge constraints"><link rel=alternate hreflang=en-us href=https://bellanich.github.io/portfolio/edge-diffusion/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#6D49FF"><script src=/js/mathjax-config.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.2.2/lazysizes.min.js integrity="sha512-TmDwFLhg3UA4ZG0Eb4MIyT1O1Mb+Oww5kFG0uHqXsdbyZz9DcvYQhKpGgNkamAI6h2lGGZq2X8ftOJvF/XjTUg==" crossorigin=anonymous async></script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.319d1d4610b53d3ccd8a5eb387a25065.css><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/images/icon_huc1af03d399f8074958ea0ac44dc20f74_179729_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/images/icon_huc1af03d399f8074958ea0ac44dc20f74_179729_192x192_fill_lanczos_center_3.png><link rel=canonical href=https://bellanich.github.io/portfolio/edge-diffusion/><meta property="twitter:card" content="summary_large_image"><meta property="og:site_name" content="Bella Nicholson"><meta property="og:url" content="https://bellanich.github.io/portfolio/edge-diffusion/"><meta property="og:title" content="Frames Per Second: Low-Latency Conditional Image Generation on a 2GB Memory Budget | Bella Nicholson"><meta property="og:description" content="A study in pushing state-of-the-art computer vision models to their performance limits on iOS, balancing model capacity against real-world edge constraints"><meta property="og:image" content="https://bellanich.github.io/portfolio/edge-diffusion/featured.png"><meta property="twitter:image" content="https://bellanich.github.io/portfolio/edge-diffusion/featured.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2025-11-30T00:00:00+00:00"><meta property="article:modified_time" content="2025-11-30T00:00:00+00:00"><title>Frames Per Second: Low-Latency Conditional Image Generation on a 2GB Memory Budget | Bella Nicholson</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper><script src=/js/wowchemy-init.min.a30802436269f02f8cb649e501c83c0c.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Bella Nicholson</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Bella Nicholson</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Bio</span></a></li><li class=nav-item><a class=nav-link href=/blog/#blog><span>Blog</span></a></li><li class=nav-item><a class=nav-link href=/experience/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/projects/#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/talks/#talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=/media/BellaNicholson_CV.pdf><span>CV</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li></ul></div></nav></div><div class=page-body><article class=article><div class="article-container pt-3"><h1>Frames Per Second: Low-Latency Conditional Image Generation on a 2GB Memory Budget</h1><div class=article-metadata><span class=article-date>Nov 30, 2025</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=/post/edge-diffusion-1><i class="fas fa-blog mr-1"></i>
Blog
</a><a class="btn btn-outline-primary btn-page-header" href=https://github.com/bellanich/pocket-diffusion target=_blank rel=noopener><i class="fab fa-github mr-1"></i>
Code</a></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:483px><div style=position:relative><img src=/portfolio/edge-diffusion/featured_hub43744d689e1c9798b87a9fc8c7268da_6010160_720x0_resize_lanczos_3.png alt class=featured-image>
<span class=article-header-caption>Image credit: <a href=https://blog.google/technology/ai/nano-banana-pro/ target=_blank rel=noopener><strong>Nano Banana Pro</strong></a></span></div></div><div class=article-container><div class=article-style><p>Running state-of-the-art computer vision entirely on-device isn’t easy — and that’s exactly why I had to try it. During last year’s <a href=../edge-llm/>adventure in embedding multimodal LLMs on edge devices</a>, the visceral impact of images really stood out to me. Unlike sequential language, the human brain processes imagery almost instantly, making its effects uniquely potent.</p><p>In recent years, the gravitational pull of Large Language Models (LLMs) has dominated the AI space, thanks to the compounding force of <a href=https://arxiv.org/abs/1706.03762 target=_blank rel=noopener>attention</a> and <a href=https://arxiv.org/pdf/2001.08361/1000 target=_blank rel=noopener>scaling laws</a>. That focus began to shift when Google DeepMind released <a href=https://aistudio.google.com/models/gemini-2-5-flash-image target=_blank rel=noopener>Nano Banana</a> in August 2025, and turned the painstaking process of photography edits into a simple text prompt. Three months later, <a href=https://blog.google/technology/ai/nano-banana-pro/ target=_blank rel=noopener>Nano Banana Pro</a> demonstrated a massive leap in generative computer vision capabilities by rendering perfectly legible text pixel by pixel. The implication? The power to instantly generate designer-quality infographics and slide decks.</p><p>Seeing that level of capability running smoothly in the cloud made me wonder: how powerful could a tiny conditional image-generation model be while still fitting into my iPhone (and not crashing it)?</p><figure><img src=images/pipeline-diagram.png style=width:35%;height:auto><figcaption><strong>Figure 1.</strong> My hyper-optimized three-stage pipeline uses <a href=https://github.com/apple/ml-stable-diffusion>Apple’s CoreML Stable Diffusion model</a> for on-device conditional image generation. By isolating the heavy diffusion step to background regeneration, the system preserves identity consistency despite the tiny model’s quality constraints. The result is lightweight, fully on-device image generation averaging ~27 seconds end-to-end.</figcaption></figure><p>That curiosity quickly launched this hands-on experiment. I challenged myself to run high-capacity, conditional image generation entirely on my iPhone&rsquo;s hardware. Unfortunately, generative quality often breaks down at smaller scales: a tiny model is more likely to turn you into a distant cousin than your doppelgänger. To solve this, I engineered a two-step workflow that preserves subject identity while regenerating complex backgrounds and enforcing visual consistency (with some fun filters included). I initially benchmarked <a href=https://huggingface.co/segmind/tiny-sd target=_blank rel=noopener>Segmind&rsquo;s Tiny (~1GB) stable diffusion model</a> due to its tiny memory footprint, but it couldn&rsquo;t generate high-quality outputs under our strict timing and hardware constraints.</p><p>The result is a fully on-device image transformation playground that tests the best of open-source conditional image generation.</p><figure style=display:flex;flex-direction:column;align-items:center;text-align:center><div style=display:flex;justify-content:center;gap:10px;align-items:flex-end><div style=width:80%;display:flex;flex-direction:column><img src=images/app-preview-1.PNG style=width:100%;height:auto;object-fit:contain><div style=margin-top:5px;font-size:.75em>(a)</div></div><div style=width:80%;display:flex;flex-direction:column><img src=images/app-preview-2.PNG style=width:100%;height:auto;object-fit:contain><div style=margin-top:5px;font-size:.75em>(b)</div></div></div><figcaption style=margin-top:15px><strong>Figure 2.</strong> My custom iOS app. In the <a href=https://www.gettyimages.com/detail/news-photo/sabrina-carpenter-at-the-2024-governors-ball-held-at-news-photo/2156108404>original image</a>, Sabrina Carpenter is performing at the 2024 Governors Ball in Queens, New York. My stable diffusion pipeline successfully transports her to the interior of Balboa Park in San Diego, California. One final filter applies a stylized aesthetic, transforming the result into an album-cover candidate.</figcaption></figure><p>For the full story, including technical details, check out my corresponding <strong>&ldquo;Frames Per Second&rdquo; blog series</strong>:</p><ul><li><a href=../../post/edge-diffusion-1/>Part 1: The Hunt for a Tiny, High-Quality Diffusion Model</a></li><li><a href=../../post/edge-diffusion-2/>Part 2: Quantization, Kernels, and the Path to On-Device Diffusion</a></li><li><a href=../../post/edge-diffusion-3/>Part 3: Turning a Tiny Diffusion Model into a Traveling Photobooth</a></li></ul><p>The complete source code, benchmarks, and project notes are available on <a href=https://github.com/bellanich/pocket-diffusion target=_blank rel=noopener>GitHub</a>. Sometimes it only takes a few frames per second to generate the image you want: no cloud, no fuss, no hassle.</p></div><div class=article-tags><a class="badge badge-light" href=/tag/code/>Code</a></div><div class=share-box aria-hidden=true><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https://bellanich.github.io/portfolio/edge-diffusion/&amp;text=Frames%20Per%20Second:%20Low-Latency%20Conditional%20Image%20Generation%20on%20a%202GB%20Memory%20Budget" target=_blank rel=noopener class=share-btn-twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https://bellanich.github.io/portfolio/edge-diffusion/&amp;t=Frames%20Per%20Second:%20Low-Latency%20Conditional%20Image%20Generation%20on%20a%202GB%20Memory%20Budget" target=_blank rel=noopener class=share-btn-facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Frames%20Per%20Second:%20Low-Latency%20Conditional%20Image%20Generation%20on%20a%202GB%20Memory%20Budget&amp;body=https://bellanich.github.io/portfolio/edge-diffusion/" target=_blank rel=noopener class=share-btn-email><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https://bellanich.github.io/portfolio/edge-diffusion/&amp;title=Frames%20Per%20Second:%20Low-Latency%20Conditional%20Image%20Generation%20on%20a%202GB%20Memory%20Budget" target=_blank rel=noopener class=share-btn-linkedin><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Frames%20Per%20Second:%20Low-Latency%20Conditional%20Image%20Generation%20on%20a%202GB%20Memory%20Budget%20https://bellanich.github.io/portfolio/edge-diffusion/" target=_blank rel=noopener class=share-btn-whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https://bellanich.github.io/portfolio/edge-diffusion/&amp;title=Frames%20Per%20Second:%20Low-Latency%20Conditional%20Image%20Generation%20on%20a%202GB%20Memory%20Budget" target=_blank rel=noopener class=share-btn-weibo><i class="fab fa-weibo"></i></a></li></ul></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by></p><p class=powered-by>Published with
<a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> —
the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script><script>const code_highlighting=!0</script><script>const search_config={indexURI:"/index.json",minLength:1,threshold:.3},i18n={no_results:"No results found",placeholder:"Search...",results:"results found"},content_type={post:"Posts",project:"Projects",publication:"Publications",event:"Events",slides:"Slides"}</script><script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/wowchemy.min.2715644373c13ab983bf49e4043ffe04.js></script></body></html>