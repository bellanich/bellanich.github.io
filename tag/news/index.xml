<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>News | Bella Nicholson</title><link>https://bellanich.github.io/tag/news/</link><atom:link href="https://bellanich.github.io/tag/news/index.xml" rel="self" type="application/rss+xml"/><description>News</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 27 Jan 2025 00:00:00 +0000</lastBuildDate><image><url>https://bellanich.github.io/images/icon_huc1af03d399f8074958ea0ac44dc20f74_179729_512x512_fill_lanczos_center_3.png</url><title>News</title><link>https://bellanich.github.io/tag/news/</link></image><item><title>Decoding Transformers: A Concise Guide to Modern ML Research</title><link>https://bellanich.github.io/post/transformers-handbook/</link><pubDate>Mon, 27 Jan 2025 00:00:00 +0000</pubDate><guid>https://bellanich.github.io/post/transformers-handbook/</guid><description>&lt;p>I&amp;rsquo;ve had a whirlwind introduction to world of LLMs. Between &lt;a href="../edge-llm/">my adventure in embedding a multi-modal foundation model on various iOS devices&lt;/a> and jetting of to &lt;a href="https://neurips.cc/Conferences/2024" target="_blank" rel="noopener">NeurIPS 2024 in Vancouver&lt;/a> ðŸ‡¨ðŸ‡¦, Iâ€™ve been immersed in all things related to LLMs.&lt;/p>
&lt;figure>
&lt;img src="neurips_conventer_center.jpg">
&lt;figcaption>
The Neural Information Processing Systems (NeurIPS) 2024 Conference took place at the beautiful Vancouver Convention Center, from December 10th to 15th (&lt;a href="https://neurips.cc/Conferences/2024">image credit&lt;/a>).
&lt;/figcaption>
&lt;/figure>
&lt;p>I&amp;rsquo;ve spent countless hours talking to the researchers building state-of-the-art LLMs and even more time pouring over online resources to understand the fundamentals. To save you the trouble, I&amp;rsquo;ve organized everything I&amp;rsquo;ve learned into &lt;a href="https://bellanich.github.io/media/transformers_handbook.pdf"> a handy study guide: &amp;ldquo;Transformers Decoded: A Quick Guide to ML Research&amp;rdquo; &lt;/a>.&lt;/p>
&lt;p>This guide explains key concepts, industry trends, and the critical optimization techniques that make LLMs so performant. We pay close attention to crucial inference optimization techniques, including:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Speculative decoding&lt;/strong>: Inference is accelerated by generating multiple candidate outputs with a smaller LLM and verifying them with a larger, more accurate LLM.&lt;/li>
&lt;li>&lt;strong>Flash attention&lt;/strong>: By restructuring the attention operations to minimize memory reads and writes â€” the bottleneck in classical attention â€” we achieve significant speedups.&lt;/li>
&lt;li>&lt;strong>Continuous batching&lt;/strong>: Incoming requests are dynamically batched to maximize hardware utilization and throughput, especially in online serving.&lt;/li>
&lt;/ul>
&lt;p>Further details on these (and other) optimization techniques can be found the PDF below. Let&amp;rsquo;s decode the latest in AI research, together!&lt;/p>
&lt;!-- Load local file -->
&lt;embed src="https://bellanich.github.io/media/transformers_handbook.pdf" width="700" height="550" type="application/pdf"></description></item><item><title>From Framework to Functionality: ðŸ“¢ My Custom Python ML Template Launch</title><link>https://bellanich.github.io/post/python-ml-template/</link><pubDate>Mon, 25 Mar 2024 00:00:00 +0000</pubDate><guid>https://bellanich.github.io/post/python-ml-template/</guid><description>&lt;p>In the past month, I&amp;rsquo;ve set up 5 different Git repositories from scratch. Each time, I found myself navigating the trade-off between creating a clean project setup and getting started quickly. While software engineering is all about navigating trade-offs, it&amp;rsquo;s also about crafting solutions that rise above them altogether.&lt;/p>
&lt;p>In this case, I found myself asking: &amp;ldquo;How few commands can I really get away with to kickstart a new machine learning (ML) project&amp;rdquo;? Well, from putting together &lt;a href="https://github.com/bellanich/python-ml-template" target="_blank" rel="noopener">this Python ML Template repository&lt;/a>, my answer is three. (See the demo above for a quick example.)&lt;/p>
&lt;p>If you&amp;rsquo;re curious about my implementation, checkout &lt;a href="https://github.com/bellanich/python-ml-template/blob/main/README.md" target="_blank" rel="noopener">my project&amp;rsquo;s README file&lt;/a> and &lt;a href="https://github.com/bellanich/python-ml-template/blob/main/docs/0_overview.md" target="_blank" rel="noopener">documentation&lt;/a>. Happy ML feature development!&lt;/p></description></item><item><title>Notes Alert: ðŸ““ A Handy 3-Page Cheatsheet for Version Control Pros</title><link>https://bellanich.github.io/post/git-cheatsheet/</link><pubDate>Tue, 31 Oct 2023 00:00:00 +0000</pubDate><guid>https://bellanich.github.io/post/git-cheatsheet/</guid><description>&lt;p>As a Machine Learning engineer, I use Git daily, but even useful commands can feel cryptic at times. I struggled to find a cheatsheet that bridged the gap between theory and real-world application. That&amp;rsquo;s why I created &lt;a href="https://nbviewer.org/github/bellanich/git-cheatsheet/blob/1dd32689009de1fdb48b49bbe2c3d437355fad91/git_cheatsheet.pdf" target="_blank" rel="noopener">my own cheatsheet&lt;/a> â€“ a resource that demystifies core concepts alongside practical commands.&lt;/p>
&lt;p>Download the PDF below, or grab &lt;a href="https://github.com/bellanich/git-cheatsheet/blob/main/README.md" target="_blank" rel="noopener">the source code&lt;/a> to customize it for your needs. Let&amp;rsquo;s up our Git game together!&lt;/p>
&lt;!-- Use nbviewer.org to automatically download and embed Git Cheatsheet directly from GitHub -->
&lt;p>&lt;embed src="git_cheatsheet.pdf" width="700" height="550"
type="application/pdf">&lt;/p></description></item></channel></rss>