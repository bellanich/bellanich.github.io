<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.0.0-beta.1 for Hugo"><meta name=author content="Bella Nicholson"><meta name=description content="For the past two months, I've been intensely studying the state-of-the-art in LLM research. This guide distills my findings into a practical resource for understanding the latest AI research."><link rel=alternate hreflang=en-us href=https://bellanich.github.io/post/transformers-handbook/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#6D49FF"><script src=/js/mathjax-config.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.2.2/lazysizes.min.js integrity="sha512-TmDwFLhg3UA4ZG0Eb4MIyT1O1Mb+Oww5kFG0uHqXsdbyZz9DcvYQhKpGgNkamAI6h2lGGZq2X8ftOJvF/XjTUg==" crossorigin=anonymous async></script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.319d1d4610b53d3ccd8a5eb387a25065.css><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/images/icon_huc1af03d399f8074958ea0ac44dc20f74_179729_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/images/icon_huc1af03d399f8074958ea0ac44dc20f74_179729_192x192_fill_lanczos_center_3.png><link rel=canonical href=https://bellanich.github.io/post/transformers-handbook/><meta property="twitter:card" content="summary_large_image"><meta property="og:site_name" content="Bella Nicholson"><meta property="og:url" content="https://bellanich.github.io/post/transformers-handbook/"><meta property="og:title" content="Decoding Transformers: A Concise Guide to Modern ML Research | Bella Nicholson"><meta property="og:description" content="For the past two months, I've been intensely studying the state-of-the-art in LLM research. This guide distills my findings into a practical resource for understanding the latest AI research."><meta property="og:image" content="https://bellanich.github.io/post/transformers-handbook/featured.png"><meta property="twitter:image" content="https://bellanich.github.io/post/transformers-handbook/featured.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2025-01-27T00:00:00+00:00"><meta property="article:modified_time" content="2025-01-27T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://bellanich.github.io/post/transformers-handbook/"},"headline":"Decoding Transformers: A Concise Guide to Modern ML Research","image":["https://bellanich.github.io/post/transformers-handbook/featured.png"],"datePublished":"2025-01-27T00:00:00Z","dateModified":"2025-01-27T00:00:00Z","author":{"@type":"Person","name":"Bella Nicholson"},"publisher":{"@type":"Organization","name":"Bella Nicholson","logo":{"@type":"ImageObject","url":"https://bellanich.github.io/images/icon_huc1af03d399f8074958ea0ac44dc20f74_179729_192x192_fill_lanczos_center_3.png"}},"description":"For the past two months, I've been intensely studying the state-of-the-art in LLM research. This guide distills my findings into a practical resource for understanding the latest AI research."}</script><title>Decoding Transformers: A Concise Guide to Modern ML Research | Bella Nicholson</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper><script src=/js/wowchemy-init.min.a30802436269f02f8cb649e501c83c0c.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Bella Nicholson</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Bella Nicholson</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Bio</span></a></li><li class=nav-item><a class=nav-link href=/blog/#blog><span>Blog</span></a></li><li class=nav-item><a class=nav-link href=/experience/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/projects/#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/talks/#talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=/media/BellaNicholson_CV.pdf><span>CV</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li></ul></div></nav></div><div class=page-body><article class=article><div class="article-container pt-3"><h1>Decoding Transformers: A Concise Guide to Modern ML Research</h1><div class=article-metadata><span class=article-date>Jan 27, 2025
</span><span class=middot-divider></span>
<span class=article-reading-time>2 min read</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=https://github.com/bellanich/python-ml-template target=_blank rel=noopener><i class="fab fa-github mr-1"></i>
Code</a></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:425px><div style=position:relative><img src=/post/transformers-handbook/featured_hud0a994bcb75c56598e3f6c86e642ea50_365723_720x0_resize_lanczos_3.png alt class=featured-image>
<span class=article-header-caption>Image from SoluLab</span></div></div><div class=article-container><div class=article-style><p>I&rsquo;ve had a whirlwind introduction to world of LLMs. Between <a href=../edge-llm/>my adventure in embedding a multi-modal foundation model on various iOS devices</a> and jetting of to <a href=https://neurips.cc/Conferences/2024 target=_blank rel=noopener>NeurIPS 2024 in Vancouver</a> ðŸ‡¨ðŸ‡¦, Iâ€™ve been immersed in all things related to LLMs.</p><figure><img src=neurips_conventer_center.jpg><figcaption>The Neural Information Processing Systems (NeurIPS) 2024 Conference took place at the beautiful Vancouver Convention Center, from December 10th to 15th (<a href=https://neurips.cc/Conferences/2024>image credit</a>).</figcaption></figure><p>I&rsquo;ve spent countless hours talking to the researchers building state-of-the-art LLMs and even more time pouring over online resources to understand the fundamentals. To save you the trouble, I&rsquo;ve organized everything I&rsquo;ve learned into <a href=/media/transformers_handbook.pdf>a handy study guide: &ldquo;Transformers Decoded: A Quick Guide to ML Research&rdquo; </a>.</p><p>This guide explains key concepts, industry trends, and the critical optimization techniques that make LLMs so performant. We pay close attention to crucial inference optimization techniques, including:</p><ul><li><strong>Speculative decoding</strong>: Inference is accelerated by generating multiple candidate outputs with a smaller LLM and verifying them with a larger, more accurate LLM.</li><li><strong>Flash attention</strong>: By restructuring the attention operations to minimize memory reads and writes â€” the bottleneck in classical attention â€” we achieve significant speedups.</li><li><strong>Continuous batching</strong>: Incoming requests are dynamically batched to maximize hardware utilization and throughput, especially in online serving.</li></ul><p>Further details on these (and other) optimization techniques can be found the PDF below. Let&rsquo;s decode the latest in AI research, together!</p><embed src=/media/transformers_handbook.pdf width=700 height=550 type=application/pdf></div><div class=article-tags><a class="badge badge-light" href=/tag/news/>News</a></div><div class=share-box aria-hidden=true><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https://bellanich.github.io/post/transformers-handbook/&amp;text=Decoding%20Transformers:%20A%20Concise%20Guide%20to%20Modern%20ML%20Research" target=_blank rel=noopener class=share-btn-twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https://bellanich.github.io/post/transformers-handbook/&amp;t=Decoding%20Transformers:%20A%20Concise%20Guide%20to%20Modern%20ML%20Research" target=_blank rel=noopener class=share-btn-facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Decoding%20Transformers:%20A%20Concise%20Guide%20to%20Modern%20ML%20Research&amp;body=https://bellanich.github.io/post/transformers-handbook/" target=_blank rel=noopener class=share-btn-email><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https://bellanich.github.io/post/transformers-handbook/&amp;title=Decoding%20Transformers:%20A%20Concise%20Guide%20to%20Modern%20ML%20Research" target=_blank rel=noopener class=share-btn-linkedin><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Decoding%20Transformers:%20A%20Concise%20Guide%20to%20Modern%20ML%20Research%20https://bellanich.github.io/post/transformers-handbook/" target=_blank rel=noopener class=share-btn-whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https://bellanich.github.io/post/transformers-handbook/&amp;title=Decoding%20Transformers:%20A%20Concise%20Guide%20to%20Modern%20ML%20Research" target=_blank rel=noopener class=share-btn-weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="article-widget content-widget-hr"><h3>Related</h3><ul><li><a href=/post/python-ml-template/>From Framework to Functionality: ðŸ“¢ My Custom Python ML Template Launch</a></li><li><a href=/post/git-cheatsheet/>Notes Alert: ðŸ““ A Handy 3-Page Cheatsheet for Version Control Pros</a></li></ul></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by></p><p class=powered-by>Published with
<a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> â€”
the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script><script>const code_highlighting=!0</script><script>const search_config={indexURI:"/index.json",minLength:1,threshold:.3},i18n={no_results:"No results found",placeholder:"Search...",results:"results found"},content_type={post:"Posts",project:"Projects",publication:"Publications",event:"Events",slides:"Slides"}</script><script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/wowchemy.min.2715644373c13ab983bf49e4043ffe04.js></script></body></html>